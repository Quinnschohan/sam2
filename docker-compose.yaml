services:
  frontend:
    image: sam2/frontend
    build:
      context: ./demo/frontend
      dockerfile: frontend.Dockerfile
    ports:
      - 7262:80

  backend:
    image: sam2/backend
    build:
      context: .
      dockerfile: backend.Dockerfile
      args:
        MODEL_SIZE: tiny
    ports:
      - 7263:5000
    volumes:
      - ./demo/data/:/data/:rw
      - ./demo/backend/server:/opt/sam2/server:rw
    environment:
      - SERVER_ENVIRONMENT=DEV
      - GUNICORN_WORKERS=1
      # Inference API needs to have at least 2 threads to handle an incoming
      # parallel cancel propagation request
      - GUNICORN_THREADS=2
      - GUNICORN_PORT=5000
      - API_URL=http://localhost:7263
      - DEFAULT_VIDEO_PATH=gallery/05_default_juggle.mp4
      # # ffmpeg/video encode settings
      - FFMPEG_NUM_THREADS=1
      - VIDEO_ENCODE_CODEC=libx264
      - VIDEO_ENCODE_CRF=23
      - VIDEO_ENCODE_FPS=24
      - VIDEO_ENCODE_MAX_WIDTH=1280
      - VIDEO_ENCODE_MAX_HEIGHT=720
      - VIDEO_ENCODE_VERBOSE=False
      # Force CPU usage on Mac
      - SAM2_DEMO_FORCE_CPU_DEVICE=1
    # Remove the command override, as it's now handled by ENTRYPOINT
    # command: >
    #   gunicorn --worker-tmp-dir /dev/shm 
    #     --worker-class gthread app:app 
    #     --log-level info 
    #     --access-logfile /dev/stdout 
    #     --log-file /dev/stderr 
    #     --workers $${GUNICORN_WORKERS} 
    #     --threads $${GUNICORN_THREADS} 
    #     --bind 0.0.0.0:$${GUNICORN_PORT} 
    #     --timeout 60 
    #     --reload
